# TEXT MINING PROJECT

## Overview
This project focuses on **text mining and classification** using **Natural Language Processing (NLP) techniques**. It involves **text preprocessing, feature extraction, and machine learning models** to classify textual data effectively. The implementation is done in Python using various **NLP and machine learning libraries**.

## Key Features
- **Text Preprocessing**: Tokenization, stopword removal, stemming, and lemmatization.
- **Feature Engineering**: TF-IDF and Count Vectorizer for feature extraction.
- **Machine Learning Models**: Implemented Decision Tree, Random Forest, SVM, and BERT for text classification.
- **Deep Learning (BERT)**: Fine-tuned transformer models for sentiment analysis.
- **Performance Evaluation**: Used accuracy, classification reports, and cross-validation.

## Technologies Used
- **Python (pandas, numpy, re, nltk, spacy)**
- **Machine Learning (scikit-learn, Decision Trees, SVM, Random Forests)**
- **Deep Learning (BERT, Transformers library)**
- **Google Colab for experimentation**

## What I Learned
- **NLP Pipeline**: Mastered text preprocessing, tokenization, and feature engineering.
- **Machine Learning & Deep Learning**: Gained experience in traditional ML models and fine-tuning transformer models.
- **Data Analysis & Evaluation**: Implemented methods to evaluate model performance effectively.
- **Hands-on AI Experience**: Worked with **BERT and transformers** for text classification.

## Usage
1. Load and preprocess textual data.
2. Extract features using TF-IDF or Count Vectorizer.
3. Train and evaluate different ML models.
4. Experiment with BERT for improved text classification.

## Contributors
- **Davide Croatto**
- **Hubert Nowak**
- **Eleonora Zullo**

